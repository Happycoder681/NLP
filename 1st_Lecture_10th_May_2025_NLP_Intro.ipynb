{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NLP is a short form for Natural Lanuage Processing. It is a field of AI that enables computers to understand, interpret and generate human language. It bridges the gap between human communication and computer processing by using algorithms and machine learning to analyze text and speech."
      ],
      "metadata": {
        "id": "aW4Nuj6DXib_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLP allows for faster typing, text prediction, auto-complete i.e providing suggestions for remaining part of the word, text messengers, search engines, websites, etc. utilize NLP technology to speed up the access to relevant information, grammar checking, helps users use punctuations, voice propositions and grammatical elememts by proving suggestions in your language.\n",
        "\n",
        "\n",
        "Spell Checker\n",
        "It help users check speling errors. eg grammarly uses both checker and grammar checker for accurate output.\n",
        "\n",
        "What NLP Does\n",
        "1. Understanding - NLP aims to make computers capable of understanding the meaning behind the text and speech including hints like sarcasm, idioms and context.\n",
        "\n",
        "2. Interpreting - It allows computers to extract information from text, identify entities and understand the sentiments or intent behind the message\n",
        "\n",
        "3. Generating - NLP can be used to create human like text wheather its writing stories, summarizing articles or generating code.\n",
        "\n",
        "\n",
        "How NLP Works ?\n",
        "\n",
        "NLP can work using machine learning models or Deep Learning models. Many times the pretrained models which are trained on vast dataset of text and speech.\n",
        "\n",
        "Examples of NLP use - Chatbot, voice assistants, translation apps, search engines, social media analysis, text summarization.\n",
        "\n",
        "NLU (understanding) is where we try to understand what huamn actally means and NLG (generation) is more about generating human like text. NLU is more difficult than NLG because of lexical ambiguty, syntactic ambiguity and referential ambiguity.\n",
        "\n",
        "lexical ambiguity means the word that holds several meanings. for eg. the man is looking for the match.\n",
        "\n",
        "syntactic ambiguity - this refers to a sequence of words with more than one meaning. For eg. The fish is ready to eat.Visiting relatives can be exhausting. this embiguity can be resolved with the help of parts of speech tagging technique.\n",
        "\n",
        "referential ambiguity - this involves a word or phrase that could refer to two or more properties. for eg. \"Tom met Jerry and John. They went to movies.\"\n",
        "\n",
        "\n",
        "\n",
        "Stages in NLP\n",
        "\n",
        "Lexical Analysis => Syantactic Analysis => Semantic Analysis => Disclosure Integration => Pragmatic Analysis\n",
        "\n",
        "Lexical Analysis is word level analysis. It is of two types stemming and lemmatization.\n",
        "\n",
        "Stemming and lemmatization - They both reduce words to their base form but they differ in their approach. Stemming cuts off word endings. for eg running to run, flies to fli. So it will not always produce meaningful words. Thats why, lemmatization is preferred which converts words to their dictionary root form considering context and grammar.\n",
        "\n",
        "Syntactic Analysis is sentence level analysis i.e checking grammar, syntactical meaning of words and relationship between them. So here dependency grammar, parts of speech tagging, NER (Named entity relationship tagging, etc is done.\n",
        "\n",
        "Semantic Analysis - It retrieves the possible meanings of a sentence that is clear and semantically correct. Its the process of retrieving meaningful insights from the text.\n",
        "\n",
        "Discourse Integration - It is like referential integrity. For eg Ram wants it. So here the reference should be correct.\n",
        "\n",
        "Pragmatic Analysis - This tries to understand context of the conversation."
      ],
      "metadata": {
        "id": "BlMnFDZgbu1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"[] - set of words\n",
        "\n",
        ". - except new line\n",
        "\n",
        "{n,m} - atleast n and upto m\n",
        "\n",
        "^ - in the beginning\n",
        "\n",
        "$ - At the end\n",
        "\n",
        "+ - 1 or more\n",
        "\n",
        "* - 0 or or more\n",
        "? - 0 or 1\n",
        "() - group of sub pattern\n",
        "\\ - escape character\n",
        "| - Or\""
      ],
      "metadata": {
        "id": "kIbrZ3Y2vjnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\A - beginning of the string\n",
        "\n",
        "\\Z - end of the string\n",
        "\n",
        "\\d - digits\n",
        "\n",
        "\\w - alphanumeric and underscore"
      ],
      "metadata": {
        "id": "stXARZbE05VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "LWw8jhHn1gRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pattern = re.compile('[abc]')  #['b', 'a', 'c', 'c']\n",
        "# pattern=re.compile('[a-c]')  #['b', 'a', 'c', 'c']\n",
        "# pattern = re.compile('[aqutijc]') # ['a', 'i', 'c', 'c', 'u', 't']\n",
        "s = \"basics of computers\"\n",
        "re.findall(pattern,s)  #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5KiH71c1t-J",
        "outputId": "e559d445-0049-46e8-8523-c5c453087ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'i', 'c', 'c', 'u', 't']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('[a-h]') # b,a,c,f,e\n",
        "s = \"basics of Computers\"\n",
        "re.findall(pattern,s)"
      ],
      "metadata": {
        "id": "yK2Et4oh168g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('[1-3]') # 3\n",
        "s = \"746583hreh\"\n",
        "re.findall(pattern,s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p__Z0h0Z2fQA",
        "outputId": "0e3f9952-00b1-439f-c1fa-5e17a70b63f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('[^1-3]') # 74658href   # jab bracket ke andar ^ aa jata h to its negation\n",
        "s = \"746583hreh\"\n",
        "re.findall(pattern,s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXLqj1Ue4ske",
        "outputId": "878633b0-b53d-42b5-f551-684b3e2334c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['7', '4', '6', '5', '8', 'h', 'r', 'e', 'h']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('[^1-3]{2,4}') # ['74', '658', 'hreh']\n",
        "s = \"7436583hreh\"\n",
        "re.findall(pattern,s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxtJk1ux5QQG",
        "outputId": "7078c664-c537-48cd-be95-c4d080504682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['74', '658', 'hreh']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile('^a....h') #\n",
        "s = \"7436583hreh\"\n",
        "result = re.match(pattern,s)\n",
        "if result:\n",
        "  print(\"Pattern Matched\")\n",
        "else:\n",
        "  print(\"Pattern Not Matched\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgGp7W0R6H61",
        "outputId": "ec9f5a26-ea6c-4b9a-fa8b-4cd878b58e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern Not Matched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heb2_5_172Fk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}